{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea046561-53c5-4044-977d-6e5df0f505e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import errno\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e931d97-d7fd-499d-be3f-773314d51d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663\n",
      "139\n",
      "(662, 1)\n",
      "(138, 1)\n"
     ]
    }
   ],
   "source": [
    "NUM_AUG_IMAGES_WANTED = 1000\n",
    "IMAGE_HEIGHT = 96\n",
    "IMAGE_WIDTH = 96\n",
    "print(len(os.listdir('ChinaSet_AllFiles/CXR_png')))\n",
    "print(len(os.listdir('MontgomerySet/CXR_png')))\n",
    "shen_image_list = os.listdir('ChinaSet_AllFiles/CXR_png')\n",
    "mont_image_list = os.listdir('MontgomerySet/CXR_png')\n",
    "df_shen = pd.DataFrame(shen_image_list, columns=['image_id'])\n",
    "df_mont = pd.DataFrame(mont_image_list, columns=['image_id'])\n",
    "df_shen = df_shen[df_shen['image_id'] != 'Thumbs.db']\n",
    "df_mont = df_mont[df_mont['image_id'] != 'Thumbs.db']\n",
    "df_shen.reset_index(inplace=True, drop=True)\n",
    "df_mont.reset_index(inplace=True, drop=True)\n",
    "print(df_shen.shape)\n",
    "print(df_mont.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5192e5b4-38b6-4212-983a-40f9c4c96be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCUCXR_0001_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCUCXR_0002_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCUCXR_0003_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCUCXR_0004_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCUCXR_0005_0.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id\n",
       "0  MCUCXR_0001_0.png\n",
       "1  MCUCXR_0002_0.png\n",
       "2  MCUCXR_0003_0.png\n",
       "3  MCUCXR_0004_0.png\n",
       "4  MCUCXR_0005_0.png"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shen.head()\n",
    "df_mont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a737f7-201c-45b3-83eb-c2f6eae55eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target(x):\n",
    "    target = int(x[-5])\n",
    "    if target == 0:\n",
    "        return 'Normal'\n",
    "    if target == 1:\n",
    "        return 'Tuberculosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71615bf3-e3dd-439c-91d1-ee6585e84b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal          80\n",
       "Tuberculosis    58\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shen['target'] = df_shen['image_id'].apply(extract_target)\n",
    "df_mont['target'] = df_mont['image_id'].apply(extract_target)\n",
    "df_shen['target'].value_counts()\n",
    "df_mont['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e662da-aef8-488c-8a17-d4d7f296374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n",
    "    \n",
    "    \"\"\"\n",
    "    Give a column in a dataframe,\n",
    "    this function takes a sample of each class and displays that\n",
    "    sample on one row. The sample size is the same as figure_cols which\n",
    "    is the number of columns in the figure.\n",
    "    Because this function takes a random sample, each time the function is run it\n",
    "    displays different images.\n",
    "    \"\"\"\n",
    "\n",
    "IMAGE_PATH = 'ChinaSet_AllFiles/CXR_png/'\n",
    "draw_category_images('target',4, df_shen, IMAGE_PATH)\n",
    "IMAGE_PATH = 'MontgomerySet/CXR_png/'\n",
    "draw_category_images('target',4, df_mont, IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ed7357-3c29-48c1-88e1-b50f4fe0641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_sizes(file_name):\n",
    "    \"\"\"\n",
    "    1. Get the shape of the image\n",
    "    2. Get the min and max pixel values in the image.\n",
    "    Getting pixel values will tell if any pre-processing has been done.\n",
    "    3. This info will be added to the original dataframe.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(IMAGE_PATH + file_name)\n",
    "    max_pixel_val = image.max()\n",
    "    min_pixel_val = image.min()\n",
    "\n",
    "    # image.shape[2] represents the number of channels: (height, width, num_channels).\n",
    "    # Here we are saying: If the shape does not have a value for num_channels (height, width)\n",
    "    # then assign 1 to the number of channels.\n",
    "    if len(image.shape) > 2: # i.e. more than two numbers in the tuple\n",
    "        output = [image.shape[0], image.shape[1], image.shape[2], max_pixel_val, min_pixel_val]\n",
    "    else:\n",
    "        output = [image.shape[0], image.shape[1], 1, max_pixel_val, min_pixel_val]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dbcbb6a-d2a5-4f23-9d0b-d0e01f667ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>target</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>c</th>\n",
       "      <th>max_pixel_val</th>\n",
       "      <th>min_pixel_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHNCXR_0001_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2919</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHNCXR_0002_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2951</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHNCXR_0003_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2945</td>\n",
       "      <td>2987</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHNCXR_0004_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2933</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHNCXR_0005_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2933</td>\n",
       "      <td>3000</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id  target     w     h  c  max_pixel_val  min_pixel_val\n",
       "0  CHNCXR_0001_0.png  Normal  2919  3000  3            255              0\n",
       "1  CHNCXR_0002_0.png  Normal  2951  3000  3            255              0\n",
       "2  CHNCXR_0003_0.png  Normal  2945  2987  3            255              0\n",
       "3  CHNCXR_0004_0.png  Normal  2933  3000  3            255              0\n",
       "4  CHNCXR_0005_0.png  Normal  2933  3000  3            255              0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PATH = 'ChinaSet_AllFiles/CXR_png/'\n",
    "m = np.stack(df_shen['image_id'].apply(read_image_sizes))\n",
    "df = pd.DataFrame(m,columns=['w','h','c','max_pixel_val','min_pixel_val'])\n",
    "df_shen = pd.concat([df_shen,df],axis=1, sort=False)\n",
    "df_shen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c9228f-9823-4689-aeb3-25a1c3668201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>target</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>c</th>\n",
       "      <th>max_pixel_val</th>\n",
       "      <th>min_pixel_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCUCXR_0001_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4020</td>\n",
       "      <td>4892</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCUCXR_0002_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4020</td>\n",
       "      <td>4892</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCUCXR_0003_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4892</td>\n",
       "      <td>4020</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCUCXR_0004_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4892</td>\n",
       "      <td>4020</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCUCXR_0005_0.png</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4892</td>\n",
       "      <td>4020</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id  target     w     h  c  max_pixel_val  min_pixel_val\n",
       "0  MCUCXR_0001_0.png  Normal  4020  4892  3            255              0\n",
       "1  MCUCXR_0002_0.png  Normal  4020  4892  3            255              0\n",
       "2  MCUCXR_0003_0.png  Normal  4892  4020  3            255              0\n",
       "3  MCUCXR_0004_0.png  Normal  4892  4020  3            255              0\n",
       "4  MCUCXR_0005_0.png  Normal  4892  4020  3            255              0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PATH = 'MontgomerySet/CXR_png/'\n",
    "m = np.stack(df_mont['image_id'].apply(read_image_sizes))\n",
    "df = pd.DataFrame(m,columns=['w','h','c','max_pixel_val','min_pixel_val'])\n",
    "df_mont = pd.concat([df_mont,df],axis=1, sort=False)\n",
    "df_mont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c2a6b19-ae30-4aae-ab51-d97ef34feb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shen['c'].value_counts()\n",
    "df_mont['c'].value_counts()\n",
    "df_mont['target'].value_counts()\n",
    "df_data = pd.concat([df_shen, df_mont], axis=0).reset_index(drop=True)\n",
    "df_data = shuffle(df_data)\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dee08320-e041-49d2-8433-44d4c5f889c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['labels'] = df_data['target'].map({'Normal':0, 'Tuberculosis':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a09cee-4e51-4132-965b-a0b3bc102a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>target</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>c</th>\n",
       "      <th>max_pixel_val</th>\n",
       "      <th>min_pixel_val</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>CHNCXR_0375_1.png</td>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>2995</td>\n",
       "      <td>2990</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>CHNCXR_0653_1.png</td>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>2550</td>\n",
       "      <td>2336</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>CHNCXR_0338_1.png</td>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>2924</td>\n",
       "      <td>2397</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>CHNCXR_0598_1.png</td>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>2179</td>\n",
       "      <td>2221</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>CHNCXR_0440_1.png</td>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>2620</td>\n",
       "      <td>2435</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_id        target     w     h  c  max_pixel_val  \\\n",
       "374  CHNCXR_0375_1.png  Tuberculosis  2995  2990  3            255   \n",
       "652  CHNCXR_0653_1.png  Tuberculosis  2550  2336  3            255   \n",
       "337  CHNCXR_0338_1.png  Tuberculosis  2924  2397  3            255   \n",
       "597  CHNCXR_0598_1.png  Tuberculosis  2179  2221  3            255   \n",
       "439  CHNCXR_0440_1.png  Tuberculosis  2620  2435  3            255   \n",
       "\n",
       "     min_pixel_val  labels  \n",
       "374              0       1  \n",
       "652              0       1  \n",
       "337              0       1  \n",
       "597              0       1  \n",
       "439              0       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45bd4b7e-a3c0-4765-a259-79c239262aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680, 8)\n",
      "(120, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Normal          61\n",
       "Tuberculosis    59\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_data['labels']\n",
    "\n",
    "df_train, df_val = train_test_split(df_data, test_size=0.15, random_state=101, stratify=y)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "\n",
    "df_train['target'].value_counts()\n",
    "df_val['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee6dd59-2ba6-474e-99b7-d1f62b5330a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'base_dir'\n",
    "try:\n",
    "    os.makedirs(base_dir)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f2df32a-0520-4a5a-b62c-7c0f31c3d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "\n",
    "try:\n",
    "    os.makedirs(train_dir)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5738f0-c383-4c46-a350-4fe240c5a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "\n",
    "try:\n",
    "    os.makedirs(val_dir)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "Normal = os.path.join(train_dir, 'Normal')\n",
    "\n",
    "try:\n",
    "    os.makedirs(Normal)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "\n",
    "Tuberculosis = os.path.join(train_dir, 'Tuberculosis')\n",
    "try:\n",
    "    os.makedirs(Tuberculosis)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ce4de49-2dfb-46c1-a32b-30e67281a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal = os.path.join(val_dir, 'Normal')\n",
    "try:\n",
    "    os.makedirs(Normal)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "Tuberculosis = os.path.join(val_dir, 'Tuberculosis')\n",
    "try:\n",
    "    os.makedirs(Tuberculosis)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfd39bbf-ae48-43af-963e-bcc57f971475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.set_index('image_id', inplace=True)\n",
    "folder_1 = os.listdir('ChinaSet_AllFiles/CXR_png')\n",
    "folder_2 = os.listdir('MontgomerySet/CXR_png')\n",
    "train_list = list(df_train['image_id'])\n",
    "val_list = list(df_val['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06eeb61f-de04-42b5-a862-2e42fd438151",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in train_list:\n",
    "\n",
    "    fname = image\n",
    "    label = df_data.loc[image,'target']\n",
    "\n",
    "    if fname in folder_1:\n",
    "        src = os.path.join('ChinaSet_AllFiles/CXR_png', fname)\n",
    "        dst = os.path.join(train_dir, label, fname)\n",
    "\n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        cv2.imwrite(dst, image)\n",
    "\n",
    "    if fname in folder_2:\n",
    "        src = os.path.join('MontgomerySet/CXR_png', fname)\n",
    "        dst = os.path.join(train_dir, label, fname)\n",
    "\n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        cv2.imwrite(dst, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3437c09f-3281-41f5-8cfe-a828b49aaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in val_list:\n",
    "\n",
    "    fname = image\n",
    "    label = df_data.loc[image,'target']\n",
    "\n",
    "    if fname in folder_1:\n",
    "        src = os.path.join('ChinaSet_AllFiles/CXR_png', fname)\n",
    "        dst = os.path.join(val_dir, label, fname)\n",
    "\n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        cv2.imwrite(dst, image)\n",
    "\n",
    "    if fname in folder_2:\n",
    "        src = os.path.join('MontgomerySet/CXR_png', fname)\n",
    "        dst = os.path.join(val_dir, label, fname)\n",
    "\n",
    "        image = cv2.imread(src)\n",
    "        image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        cv2.imwrite(dst, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e9994f-1ca9-4163-9f3b-4c47f531ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n",
      "1060\n",
      "157\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('base_dir/train_dir/Normal')))\n",
    "print(len(os.listdir('base_dir/train_dir/Tuberculosis')))\n",
    "print(len(os.listdir('base_dir/val_dir/Normal')))\n",
    "print(len(os.listdir('base_dir/val_dir/Tuberculosis')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "785f634b-54fe-4fb9-816e-33994e85da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1095 images belonging to 1 classes.\n",
      "Found 1060 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "class_list = ['Normal','Tuberculosis']\n",
    "for item in class_list:\n",
    "    aug_dir = 'aug_dir'\n",
    "    os.mkdir(aug_dir)\n",
    "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
    "    os.mkdir(img_dir)\n",
    "    img_class = item\n",
    "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
    "    for fname in img_list:\n",
    "            src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
    "            dst = os.path.join(img_dir, fname)\n",
    "            shutil.copyfile(src, dst)\n",
    "    path = aug_dir\n",
    "    save_path = 'base_dir/train_dir/' + img_class\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    batch_size = 50\n",
    "\n",
    "    aug_datagen = datagen.flow_from_directory(path,\n",
    "                                           save_to_dir=save_path,\n",
    "                                           save_format='png',\n",
    "                                                    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "                                                    batch_size=batch_size)\n",
    "    num_files = len(os.listdir(img_dir))\n",
    "    num_batches = int(np.ceil((NUM_AUG_IMAGES_WANTED-num_files)/batch_size))\n",
    "    for i in range(0,num_batches):\n",
    "        imgs, labels = next(aug_datagen)\n",
    "    shutil.rmtree('aug_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b24cc031-776a-41c4-b781-371919e8fe0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n",
      "1060\n",
      "157\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('base_dir/train_dir/Normal')))\n",
    "print(len(os.listdir('base_dir/train_dir/Tuberculosis')))\n",
    "print(len(os.listdir('base_dir/val_dir/Normal')))\n",
    "print(len(os.listdir('base_dir/val_dir/Tuberculosis')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11308d33-4df6-4eb2-96b9-a47cedf84d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "valid_path = 'base_dir/val_dir'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40ea72d7-b8b2-4a38-acac-f751f08b6baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2155 images belonging to 2 classes.\n",
      "Found 303 images belonging to 2 classes.\n",
      "Found 303 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "test_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c58d5de2-ca94-4593-852a-973df9d49b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c5f4e17-d297-40a1-810b-3141ce0ae64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 94, 94, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 92, 92, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 90, 90, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 45, 45, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 45, 45, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 43, 43, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 41, 41, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 39, 39, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 19, 19, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 19, 19, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 13, 13, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1179904   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,661,186\n",
      "Trainable params: 1,661,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishu0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu',\n",
    "                 input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(Adam(lr=0.0001), loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7e11458-2316-4c07-88f4-7482e4abb96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model to project\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishu0\\AppData\\Local\\Temp\\ipykernel_2148\\3619227873.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 26s - loss: 0.6932 - accuracy: 0.5274 - val_loss: 0.6930 - val_accuracy: 0.4917 - lr: 1.0000e-04 - 26s/epoch - 386ms/step\n",
      "Epoch 2/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.6930 - accuracy: 0.5156 - val_loss: 0.6921 - val_accuracy: 0.8083 - lr: 1.0000e-04 - 24s/epoch - 351ms/step\n",
      "Epoch 3/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 25s - loss: 0.6931 - accuracy: 0.5426 - val_loss: 0.6898 - val_accuracy: 0.4833 - lr: 1.0000e-04 - 25s/epoch - 364ms/step\n",
      "Epoch 4/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.6932 - accuracy: 0.4948 - val_loss: 0.6915 - val_accuracy: 0.5500 - lr: 1.0000e-04 - 24s/epoch - 353ms/step\n",
      "Epoch 5/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 25s - loss: 0.6907 - accuracy: 0.5309 - val_loss: 0.6861 - val_accuracy: 0.7333 - lr: 1.0000e-04 - 25s/epoch - 367ms/step\n",
      "Epoch 6/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.6864 - accuracy: 0.5456 - val_loss: 0.6935 - val_accuracy: 0.4250 - lr: 1.0000e-04 - 27s/epoch - 392ms/step\n",
      "Epoch 7/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.6929 - accuracy: 0.5338 - val_loss: 0.6907 - val_accuracy: 0.5500 - lr: 1.0000e-04 - 24s/epoch - 358ms/step\n",
      "Epoch 8/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.6797 - accuracy: 0.5956 - val_loss: 0.6893 - val_accuracy: 0.6333 - lr: 1.0000e-04 - 24s/epoch - 356ms/step\n",
      "Epoch 9/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 25s - loss: 0.6563 - accuracy: 0.6265 - val_loss: 0.6896 - val_accuracy: 0.6167 - lr: 1.0000e-04 - 25s/epoch - 364ms/step\n",
      "Epoch 10/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.6733 - accuracy: 0.6103 - val_loss: 0.6129 - val_accuracy: 0.7000 - lr: 1.0000e-04 - 24s/epoch - 359ms/step\n",
      "Epoch 11/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 25s - loss: 0.6313 - accuracy: 0.6544 - val_loss: 0.5727 - val_accuracy: 0.7333 - lr: 1.0000e-04 - 25s/epoch - 373ms/step\n",
      "Epoch 12/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.6042 - accuracy: 0.6897 - val_loss: 0.5750 - val_accuracy: 0.6583 - lr: 1.0000e-04 - 27s/epoch - 392ms/step\n",
      "Epoch 13/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.5875 - accuracy: 0.6963 - val_loss: 0.5465 - val_accuracy: 0.7500 - lr: 1.0000e-04 - 27s/epoch - 399ms/step\n",
      "Epoch 14/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.5525 - accuracy: 0.7471 - val_loss: 0.5283 - val_accuracy: 0.8167 - lr: 1.0000e-04 - 27s/epoch - 397ms/step\n",
      "Epoch 15/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 25s - loss: 0.5787 - accuracy: 0.7147 - val_loss: 0.5641 - val_accuracy: 0.7250 - lr: 1.0000e-04 - 25s/epoch - 362ms/step\n",
      "Epoch 16/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.5674 - accuracy: 0.7200 - val_loss: 0.4427 - val_accuracy: 0.8583 - lr: 1.0000e-04 - 24s/epoch - 356ms/step\n",
      "Epoch 17/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.5667 - accuracy: 0.6956 - val_loss: 0.6932 - val_accuracy: 0.4500 - lr: 1.0000e-04 - 24s/epoch - 355ms/step\n",
      "Epoch 18/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.6824 - accuracy: 0.5368 - val_loss: 0.6863 - val_accuracy: 0.5083 - lr: 1.0000e-04 - 24s/epoch - 352ms/step\n",
      "Epoch 19/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 30s - loss: 0.6721 - accuracy: 0.5632 - val_loss: 0.4649 - val_accuracy: 0.8167 - lr: 1.0000e-04 - 30s/epoch - 448ms/step\n",
      "Epoch 20/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 28s - loss: 0.5271 - accuracy: 0.7632 - val_loss: 0.4870 - val_accuracy: 0.7917 - lr: 1.0000e-04 - 28s/epoch - 405ms/step\n",
      "Epoch 21/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 25s - loss: 0.5350 - accuracy: 0.7353 - val_loss: 0.5626 - val_accuracy: 0.7167 - lr: 1.0000e-04 - 25s/epoch - 367ms/step\n",
      "Epoch 22/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.5300 - accuracy: 0.7632 - val_loss: 0.4506 - val_accuracy: 0.7917 - lr: 1.0000e-04 - 23s/epoch - 332ms/step\n",
      "Epoch 23/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.5333 - accuracy: 0.7294 - val_loss: 0.4628 - val_accuracy: 0.8083 - lr: 1.0000e-04 - 23s/epoch - 339ms/step\n",
      "Epoch 24/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.4848 - accuracy: 0.7838 - val_loss: 0.4686 - val_accuracy: 0.8250 - lr: 1.0000e-04 - 23s/epoch - 334ms/step\n",
      "Epoch 25/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.4786 - accuracy: 0.7926 - val_loss: 0.6394 - val_accuracy: 0.6417 - lr: 1.0000e-04 - 27s/epoch - 398ms/step\n",
      "Epoch 26/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.5361 - accuracy: 0.7559 - val_loss: 0.5624 - val_accuracy: 0.7250 - lr: 1.0000e-04 - 23s/epoch - 336ms/step\n",
      "Epoch 27/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.5123 - accuracy: 0.7485 - val_loss: 0.4744 - val_accuracy: 0.8000 - lr: 1.0000e-04 - 27s/epoch - 400ms/step\n",
      "Epoch 28/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.5003 - accuracy: 0.7618 - val_loss: 0.4366 - val_accuracy: 0.8167 - lr: 1.0000e-04 - 27s/epoch - 391ms/step\n",
      "Epoch 29/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.4693 - accuracy: 0.7853 - val_loss: 0.4029 - val_accuracy: 0.8167 - lr: 1.0000e-04 - 24s/epoch - 355ms/step\n",
      "Epoch 30/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.5025 - accuracy: 0.7603 - val_loss: 0.3688 - val_accuracy: 0.8500 - lr: 1.0000e-04 - 24s/epoch - 353ms/step\n",
      "Epoch 31/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.5095 - accuracy: 0.7691 - val_loss: 0.4876 - val_accuracy: 0.7917 - lr: 1.0000e-04 - 23s/epoch - 331ms/step\n",
      "Epoch 32/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.5316 - accuracy: 0.7294 - val_loss: 0.4886 - val_accuracy: 0.8083 - lr: 1.0000e-04 - 23s/epoch - 343ms/step\n",
      "Epoch 33/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.5019 - accuracy: 0.7706 - val_loss: 0.4355 - val_accuracy: 0.7833 - lr: 1.0000e-04 - 24s/epoch - 352ms/step\n",
      "Epoch 34/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.5009 - accuracy: 0.7630 - val_loss: 0.5267 - val_accuracy: 0.6750 - lr: 1.0000e-04 - 24s/epoch - 355ms/step\n",
      "Epoch 35/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.4820 - accuracy: 0.7735 - val_loss: 0.3819 - val_accuracy: 0.8667 - lr: 1.0000e-04 - 24s/epoch - 358ms/step\n",
      "Epoch 36/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.4702 - accuracy: 0.7704 - val_loss: 0.4390 - val_accuracy: 0.7917 - lr: 1.0000e-04 - 23s/epoch - 337ms/step\n",
      "Epoch 37/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 22s - loss: 0.4905 - accuracy: 0.7570 - val_loss: 0.4690 - val_accuracy: 0.7500 - lr: 1.0000e-04 - 22s/epoch - 330ms/step\n",
      "Epoch 38/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.4878 - accuracy: 0.7691 - val_loss: 0.4608 - val_accuracy: 0.8000 - lr: 1.0000e-04 - 27s/epoch - 393ms/step\n",
      "Epoch 39/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.4818 - accuracy: 0.7735 - val_loss: 0.4496 - val_accuracy: 0.8000 - lr: 1.0000e-04 - 23s/epoch - 338ms/step\n",
      "Epoch 40/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 25s - loss: 0.4793 - accuracy: 0.7721 - val_loss: 0.4346 - val_accuracy: 0.8417 - lr: 1.0000e-04 - 25s/epoch - 364ms/step\n",
      "Epoch 41/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.4762 - accuracy: 0.7853 - val_loss: 0.3939 - val_accuracy: 0.8500 - lr: 1.0000e-04 - 23s/epoch - 343ms/step\n",
      "Epoch 42/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 26s - loss: 0.4625 - accuracy: 0.7853 - val_loss: 0.4180 - val_accuracy: 0.7833 - lr: 1.0000e-04 - 26s/epoch - 376ms/step\n",
      "Epoch 43/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.4657 - accuracy: 0.7676 - val_loss: 0.4264 - val_accuracy: 0.8500 - lr: 1.0000e-04 - 23s/epoch - 344ms/step\n",
      "Epoch 44/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.4685 - accuracy: 0.7911 - val_loss: 0.3827 - val_accuracy: 0.8667 - lr: 1.0000e-04 - 24s/epoch - 347ms/step\n",
      "Epoch 45/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.4651 - accuracy: 0.7912 - val_loss: 0.4478 - val_accuracy: 0.7917 - lr: 1.0000e-04 - 27s/epoch - 401ms/step\n",
      "Epoch 46/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.4644 - accuracy: 0.7956 - val_loss: 0.4196 - val_accuracy: 0.8417 - lr: 1.0000e-04 - 24s/epoch - 360ms/step\n",
      "Epoch 47/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 23s - loss: 0.4692 - accuracy: 0.7897 - val_loss: 0.4197 - val_accuracy: 0.8000 - lr: 1.0000e-04 - 23s/epoch - 343ms/step\n",
      "Epoch 48/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.4621 - accuracy: 0.7837 - val_loss: 0.5022 - val_accuracy: 0.7833 - lr: 1.0000e-04 - 27s/epoch - 390ms/step\n",
      "Epoch 49/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 27s - loss: 0.4623 - accuracy: 0.7912 - val_loss: 0.4184 - val_accuracy: 0.7750 - lr: 1.0000e-04 - 27s/epoch - 397ms/step\n",
      "Epoch 50/50\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "68/68 - 24s - loss: 0.4934 - accuracy: 0.7763 - val_loss: 0.3942 - val_accuracy: 0.8250 - lr: 1.0000e-04 - 24s/epoch - 359ms/step\n"
     ]
    }
   ],
   "source": [
    "filepath = \"model_v2.h5\"\n",
    "print(\"saved model to project\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,\n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n",
    "                            validation_data=val_gen,\n",
    "                            validation_steps=val_steps,\n",
    "                            epochs=50, verbose=2,\n",
    "                           callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a13bb8e-2d37-42a9-8ed0-c2a041f08d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92c315aa-53b7-4ebe-9914-3affa9b3a8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishu0\\AppData\\Local\\Temp\\ipykernel_2148\\517192584.py:3: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  model.evaluate_generator(test_gen,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.35118693113327026\n",
      "val_acc: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model_v2.h5')\n",
    "val_loss, val_acc = \\\n",
    "model.evaluate_generator(test_gen,\n",
    "                        steps=val_steps)\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_acc:', val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
